const axios = require("axios");
const path = require("path");
const fs = require("fs");
const OpenAI = require("openai");
const FormData = require("form-data");
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });


// generateTTS vocal 
async function generateTTS(text) {
  try {
    const response = await openai.audio.speech.create({
      model: "tts-1",
      voice: "alloy",     // tu peux changer la voix si tu veux
      input: text,
      format: "wav"       // format mp3, tu peux aussi essayer wav
    });

    // R√©cup√©rer le buffer audio (la r√©ponse est un ReadableStream ou Blob selon version)
    const buffer = await response.arrayBuffer();
    return Buffer.from(buffer);

  } catch (error) {
    console.error("Erreur g√©n√©ration TTS :", error);
    throw error;
  }
}

module.exports = {
  // ... tes autres exports
  generateTTS,
};

// === Fonction pour appeler OpenAI Chat ===
exports.askOpenAI = async (prompt, userText) => {
  try {
    console.log("üü° Prompt system envoy√© √† OpenAI :\n", prompt);
    console.log("üü¢ Message user envoy√© √† OpenAI :\n", userText);

    const response = await axios.post(
      "https://api.openai.com/v1/chat/completions",
      {
        model: "chatgpt-4o-latest", // plus rapide
        messages: [
          { role: "system", content: prompt },
          { role: "user", content: userText }
        ],
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        },
      }
    );

    console.log("‚úÖ R√©ponse OpenAI re√ßue :\n", response.data.choices[0].message.content);
    return response.data.choices[0].message.content;

  } catch (error) {
    console.error("‚ùå Erreur appel OpenAI :", error.response?.data || error.message);
    throw new Error("Erreur OpenAI");
  }
};

// === Fonction pour transcription audio avec Whisper ===
exports.transcribeAudio = async (filePath) => {
  try {
    console.log("üü° D√©but transcription audio, fichier :", filePath);

    // V√©rifier extension
    let ext = path.extname(filePath);
    if (!ext) {
      const newFilePath = filePath + '.wav'; // forcer extension .wav
      fs.renameSync(filePath, newFilePath);
      filePath = newFilePath;
      console.log("‚ÑπÔ∏è Fichier renomm√© avec extension :", filePath);
    } else {
      console.log("‚ÑπÔ∏è Extension fichier d√©tect√©e :", ext);
    }

    const fileStream = fs.createReadStream(filePath);

    const formData = new FormData();
    formData.append('file', fileStream);
    formData.append('model', 'whisper-1');
    formData.append('language', 'fr'); // Forcer la langue fran√ßaise

    console.log("üì§ Envoi du fichier √† OpenAI Whisper...");

    const response = await axios.post(
      'https://api.openai.com/v1/audio/transcriptions',
      formData,
      {
        headers: {
          ...formData.getHeaders(),
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        },
      }
    );

    console.log("‚úÖ Transcription re√ßue :", response.data.text);
    return response.data.text;

  } catch (error) {
    console.error("‚ùå Erreur transcription Whisper :", error.response?.data || error.message);
    throw new Error("Erreur transcription Whisper");
  }
};


