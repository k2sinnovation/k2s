const WebSocket = require("ws");

// Stocker les sockets GPT par deviceId
const gptSockets = new Map(); // Map<deviceId, { ws, isReady }>

/**
 * Envoie un chunk audio PCM √† GPT et commit si demand√©
 * @param {string} deviceId - ID du device Flutter
 * @param {string} audioBase64 - chunk audio PCM Base64
 * @param {Map} wsClients - Map<deviceId, { ws: WebSocket }>
 * @param {boolean} commit - true si c'est le dernier chunk du segment
 */
async function processAudioChunk(deviceId, audioBase64, wsClients, commit = false) {
  console.log(`[Assembly][${deviceId}] üì• Chunk re√ßu (${audioBase64.length} chars, commit: ${commit})`);
  
  // Nettoyage du Base64
  const base64Data = audioBase64.includes(",") ? audioBase64.split(",")[1] : audioBase64;
  const audioBuffer = Buffer.from(base64Data, "base64");
  console.log(`[Assembly][${deviceId}] üîÑ Buffer: ${audioBuffer.length} bytes`);

  // Cr√©er socket GPT si n'existe pas
  if (!gptSockets.has(deviceId)) {
    console.log(`[Assembly][${deviceId}] üÜï Cr√©ation connexion GPT...`);
    
    const wsGPT = new WebSocket(
      "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01",
      { 
        headers: { 
          "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
          "OpenAI-Beta": "realtime=v1"
        } 
      }
    );

    // Variables pour suivre l'√©tat
    let isSessionReady = false;
    let audioChunkCount = 0;

    wsGPT.on("open", () => {
      console.log(`[GPT][${deviceId}] ‚úÖ Connexion ouverte`);
      
      // Configuration optimale pour streaming
      wsGPT.send(JSON.stringify({
        type: "session.update",
        session: {
          modalities: ["text", "audio"],
          instructions: "Tu es un assistant vocal intelligent. R√©ponds de mani√®re concise et naturelle.",
          voice: "alloy",
          input_audio_format: "pcm16",
          output_audio_format: "pcm16",
          input_audio_transcription: {
            model: "whisper-1"
          },
          turn_detection: {
            type: "server_vad",
            threshold: 0.5,
            prefix_padding_ms: 300,
            silence_duration_ms: 700
          },
          max_response_output_tokens: 4096,
          temperature: 0.8
        }
      }));
      
      console.log(`[GPT][${deviceId}] ‚öôÔ∏è Session configur√©e`);
    });

    wsGPT.on("message", (data) => {
      let msg;
      try { 
        msg = JSON.parse(data.toString()); 
      } catch (e) { 
        console.warn(`[GPT][${deviceId}] ‚ö†Ô∏è Erreur parsing message:`, e.message); 
        return; 
      }

      // Log minimal pour √©viter spam
      if (msg.type !== "response.audio.delta") {
        console.log(`[GPT][${deviceId}] üì® Type: ${msg.type}`);
      }

      // Marquer session comme pr√™te
      if (msg.type === "session.created" || msg.type === "session.updated") {
        isSessionReady = true;
        console.log(`[GPT][${deviceId}] ‚öôÔ∏è Session pr√™te`);
      }

      // R√©cup√©ration du client Flutter
      const clientData = wsClients.get(deviceId);
      if (!clientData || !clientData.ws) {
        console.warn(`[GPT][${deviceId}] ‚ö†Ô∏è Client Flutter non trouv√©`);
        return;
      }
      const wsClient = clientData.ws;

      if (wsClient.readyState !== WebSocket.OPEN) {
        console.warn(`[GPT][${deviceId}] ‚ö†Ô∏è WebSocket Flutter ferm√©`);
        return;
      }

      // === Transcription Audio Input ===
      if (msg.type === "conversation.item.input_audio_transcription.completed") {
        console.log(`[GPT][${deviceId}] üé§ Transcription: "${msg.transcript}"`);
        wsClient.send(JSON.stringify({
          type: 'input_transcription',
          deviceId,
          transcript: msg.transcript,
          index: Date.now(),
        }));
      }

      // === Audio Delta - STREAMING IMM√âDIAT ===
      if (msg.type === "response.audio.delta") {
        audioChunkCount++;
        const audioChunk = msg.delta;
        
        if (audioChunk && audioChunk.length > 0) {
          // Log tous les 10 chunks pour √©viter spam
          if (audioChunkCount % 10 === 0) {
            console.log(`[GPT][${deviceId}] üîä Audio chunks: ${audioChunkCount} (dernier: ${audioChunk.length} chars)`);
          }
          
          // Envoi imm√©diat au client Flutter
          wsClient.send(JSON.stringify({
            type: 'response.output_audio.delta',
            deviceId,
            delta: audioChunk,
            index: audioChunkCount,
          }));
        }
      }

      // === Transcript Delta ===
      if (msg.type === "response.audio_transcript.delta") {
        console.log(`[GPT][${deviceId}] üì¢ Transcript: "${msg.delta}"`);
        wsClient.send(JSON.stringify({
          type: 'response.output_audio_transcript.delta',
          deviceId,
          delta: msg.delta,
          index: Date.now(),
        }));
      }

      // === Fin de R√©ponse ===
      if (msg.type === "response.done") {
        console.log(`[GPT][${deviceId}] ‚úÖ R√©ponse compl√®te (${audioChunkCount} chunks audio)`);
        audioChunkCount = 0;
        
        wsClient.send(JSON.stringify({
          type: 'response.completed',
          deviceId,
          index: Date.now(),
        }));
      }

      // === Erreurs ===
      if (msg.type === "error") {
        console.error(`[GPT][${deviceId}] ‚ùå Erreur:`, msg.error?.message || JSON.stringify(msg));
        wsClient.send(JSON.stringify({
          type: 'gpt_error',
          deviceId,
          error: msg.error?.message || 'Erreur GPT',
          index: Date.now(),
        }));
      }
    });

    wsGPT.on("close", (code, reason) => {
      console.log(`[GPT][${deviceId}] üîå Connexion ferm√©e (code: ${code}, reason: ${reason})`);
      gptSockets.delete(deviceId);
    });

    wsGPT.on("error", (err) => {
      console.error(`[GPT][${deviceId}] ‚ùå Erreur WebSocket:`, err.message);
      gptSockets.delete(deviceId);
    });

    gptSockets.set(deviceId, { ws: wsGPT, isReady: false });
    
    // Attendre que la session soit configur√©e
    console.log(`[GPT][${deviceId}] ‚è≥ Attente session ready...`);
    await new Promise((resolve) => {
      const checkReady = setInterval(() => {
        if (isSessionReady) {
          clearInterval(checkReady);
          const socketData = gptSockets.get(deviceId);
          if (socketData) socketData.isReady = true;
          console.log(`[GPT][${deviceId}] ‚úÖ Session ready confirm√©e`);
          resolve();
        }
      }, 100);
      
      // Timeout 5s
      setTimeout(() => {
        clearInterval(checkReady);
        console.warn(`[GPT][${deviceId}] ‚ö†Ô∏è Timeout session ready`);
        resolve();
      }, 5000);
    });
  }

  // Envoyer chunk √† GPT
  const socketData = gptSockets.get(deviceId);
  if (!socketData?.ws || socketData.ws.readyState !== WebSocket.OPEN) {
    console.error(`[Assembly][${deviceId}] ‚ùå Socket GPT non disponible (state: ${socketData?.ws?.readyState})`);
    return;
  }

  const wsGPT = socketData.ws;

  // Attendre que la session soit pr√™te
  if (!socketData.isReady) {
    console.log(`[Assembly][${deviceId}] ‚è≥ Attente session pr√™te...`);
    await new Promise(resolve => setTimeout(resolve, 500));
  }

  // Envoyer audio
  const audioPayload = {
    type: "input_audio_buffer.append",
    audio: audioBuffer.toString("base64"),
  };
  
  wsGPT.send(JSON.stringify(audioPayload));
  console.log(`[Assembly][${deviceId}] üì§ Chunk envoy√© √† GPT (${audioBuffer.length} bytes)`);

  // Si commit, d√©clencher la r√©ponse
  if (commit) {
    console.log(`[Assembly][${deviceId}] üèÅ Commit du buffer audio...`);
    
    wsGPT.send(JSON.stringify({ 
      type: "input_audio_buffer.commit" 
    }));
    
    // Petit d√©lai avant de cr√©er la r√©ponse
    await new Promise(resolve => setTimeout(resolve, 100));
    
    console.log(`[Assembly][${deviceId}] üéØ Cr√©ation de la r√©ponse...`);
    
    wsGPT.send(JSON.stringify({ 
      type: "response.create",
      response: {
        modalities: ["text", "audio"],
        instructions: "R√©ponds de mani√®re naturelle et concise √† ce qui vient d'√™tre dit."
      }
    }));
    
    console.log(`[Assembly][${deviceId}] ‚úÖ R√©ponse cr√©√©e, en attente de la g√©n√©ration GPT...`);
  }
}

// Nettoyage p√©riodique des sockets inactifs
setInterval(() => {
  let cleaned = 0;
  gptSockets.forEach((data, deviceId) => {
    if (data.ws.readyState === WebSocket.CLOSED) {
      console.log(`[Assembly][${deviceId}] üßπ Nettoyage socket ferm√©`);
      gptSockets.delete(deviceId);
      cleaned++;
    }
  });
  if (cleaned > 0) {
    console.log(`[Assembly] üßπ ${cleaned} socket(s) nettoy√©(s)`);
  }
}, 60000); // Toutes les 60s

module.exports = { processAudioChunk };
