const fs = require('fs');
const axios = require('axios');
const OpenAI = require('openai');
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const { promptTTSVocal } = require('../utils/promptsTTSVocal');

console.log("ASSEMBLYAI_API_KEY:", process.env.ASSEMBLYAI_API_KEY);

// ------------------------
// Google TTS
// ------------------------
async function generateGoogleTTSMP3(text) {
    try {
        const apiKey = process.env.K2S_IQ_Speech_API;
        console.log("[Google TTS] Texte envoy√© :", text);
        const response = await axios.post(
            `https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`,
            {
                input: { text },
                voice: { languageCode: 'fr-FR', name: 'fr-FR-Chirp3-HD-Leda', ssmlGender: 'FEMALE' },
                audioConfig: { audioEncoding: "LINEAR16" }
            }
        );
        console.log("[Google TTS] R√©ponse re√ßue. Taille Base64 :", response.data.audioContent.length);
        return response.data.audioContent;
    } catch (error) {
        console.error("[Google TTS] Erreur :", error.message);
        return null;
    }
}

// ------------------------
// D√©codage Base64
// ------------------------
function decodeBase64Audio(base64String) {
    const base64Data = base64String.replace(/^data:audio\/\w+;base64,/, '');
    return Buffer.from(base64Data, 'base64');
}

// ------------------------
// Transcription AssemblyAI (sans fichier local)
// ------------------------
async function transcribeWithAssembly(audioInput, isBase64 = false) {
    try {
        console.log("[AssemblyAI] Pr√©paration de l'audio...");
        // On utilise directement le buffer, plus de lecture fichier
        const fileData = isBase64 ? decodeBase64Audio(audioInput) : audioInput;

        const uploadResponse = await axios.post(
            'https://api.assemblyai.com/v2/upload',
            fileData,
            {
                headers: {
                    authorization: process.env.ASSEMBLYAI_API_KEY,
                    'content-type': 'application/octet-stream'
                }
            }
        );
        const uploadUrl = uploadResponse.data.upload_url;
        console.log("[AssemblyAI] Audio upload√© :", uploadUrl);

        const transcriptResponse = await axios.post(
            'https://api.assemblyai.com/v2/transcript',
            { audio_url: uploadUrl, speech_model: 'universal', language_code: 'fr' },
            { headers: { authorization: process.env.ASSEMBLYAI_API_KEY } }
        );

        const transcriptId = transcriptResponse.data.id;
        console.log("[AssemblyAI] ID transcription :", transcriptId);
        const pollingEndpoint = `https://api.assemblyai.com/v2/transcript/${transcriptId}`;

        // Polling pour r√©cup√©rer la transcription compl√®te
        while (true) {
            const result = await axios.get(pollingEndpoint, {
                headers: { authorization: process.env.ASSEMBLYAI_API_KEY }
            });
            if (result.data.status === 'completed') {
                console.log("[AssemblyAI] Transcription termin√©e :", result.data.text);
                return result.data.text;
            } else if (result.data.status === 'error') {
                throw new Error(result.data.error);
            } else {
                console.log("[AssemblyAI] Transcription en cours...");
                await new Promise(resolve => setTimeout(resolve, 3000));
            }
        }
    } catch (err) {
        console.error("[AssemblyAI] Erreur transcription :", err.message);
        throw err;
    }
}

// ------------------------
// Processus complet : Audio ‚Üí AssemblyAI ‚Üí GPT ‚Üí TTS (sans fichier temporaire)
// ------------------------
async function processAudioAndReturnJSON(fileOrBase64, isBase64 = false) {
    // On convertit directement en Buffer si base64
    const audioBuffer = isBase64 ? decodeBase64Audio(fileOrBase64) : fileOrBase64;

    let texteTranscrit = "";
    let gptResponse = "";
    const audioSegments = [];

    console.log("[ProcessAudio] D√©but traitement audio direct...");

// 1Ô∏è‚É£ Transcription
try {
    texteTranscrit = await transcribeWithAssembly(audioBuffer, false);
    console.log("[ProcessAudio] Texte transcrit :", texteTranscrit);

    // üîπ Renvoi imm√©diat au frontend ou appel callback
    if (typeof onTranscriptionReady === "function") {
        onTranscriptionReady(texteTranscrit);
    }

} catch (assemblyError) {
    console.error("[ProcessAudio] Erreur AssemblyAI :", assemblyError.message);
}

// 2Ô∏è‚É£ GPT
try {
    const completion = await openai.chat.completions.create({
        model: "gpt-5-chat-latest",
        messages: [
            { role: "system", content: promptTTSVocal },
            { role: "user", content: texteTranscrit },
        ],
    });
    gptResponse = completion.choices[0].message.content;
    console.log("[ProcessAudio] R√©ponse GPT :", gptResponse);

    // üîπ Renvoi imm√©diat de la r√©ponse GPT
    if (typeof onGPTResponseReady === "function") {
        onGPTResponseReady(gptResponse);
    }

} catch (gptError) {
    console.error("[ProcessAudio] Erreur GPT :", gptError.message);
    gptResponse = "";
}

// 3Ô∏è‚É£ TTS ...
// Tu peux continuer la g√©n√©ration TTS phrase par phrase
// et renvoyer chaque segment d√®s qu'il est pr√™t
for (let i = 0; i < sentences.length; i++) {
    const segmentAudio = await generateGoogleTTSMP3(sentences[i]);
    if (segmentAudio && typeof onTTSSegmentReady === "function") {
        onTTSSegmentReady(i, segmentAudio, sentences[i]);
    }
}

// On peut toujours retourner tout √† la fin si besoin
return { transcription: texteTranscrit, gptResponse, audioSegments };

}


// ------------------------
// Export
// ------------------------
module.exports = {
    transcribeWithAssembly,
    generateGoogleTTSMP3,
    processAudioAndReturnJSON,
    decodeBase64Audio,
};
